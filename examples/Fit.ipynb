{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DECODE - Fit SMLM Data\n",
    "The purpose of this notebook is to demonstrate the fitting procedure for a pretrained model.\n",
    "Please be advised to have a read of the Introduction notebook first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# To be removed\n",
    "import os\n",
    "os.chdir('/home/lucas/RemoteDeploy/DeepSMLM/')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import decode\n",
    "import decode.utils\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set parameters\n",
    "Set device for inference (i.e. CUDA vs. CPU) and some other parameters which only need to be changed if you know what\n",
    " you are doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'  # or 'cpu'\n",
    "\n",
    "# change only if you know what you are doing\n",
    "post_raw_th = 0.1  # post-processing initial threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load Example data\n",
    "We provide several example data for trying out DECODE.\n",
    "For this we load a gateway file which includes the links to the respective data."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gateway = decode.utils.example_helper.load_gateway()\n",
    "\n",
    "# dir where to store example data, leave as '' to store in current folder\n",
    "path = Path('')\n",
    "\n",
    "# change here for other files\n",
    "package = gateway['examples']['package_1']\n",
    "frame_path, model_path, param_path = decode.utils.example_helper.load_example_package(path=path / package['name'],\n",
    "                                                                        url=package['url'], hash=package['hash'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Frames\n",
    "Load TIFF file.\n",
    "Change only needed if you load a custom tif file.\n",
    "Note that the TIFF loader will auto-load and concatenate tiff files\n",
    "that are consecutive and share\n",
    "the same meta data. For example specifying `dummy.tif` will also load  `dummy_0.tif, dummy_1.tif` if present in the\n",
    "same folder.\n",
    "If you have single page tiff files, you can also specify a folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# depends on your input, e.g. load a tiff\n",
    "frames = decode.utils.frames_io.load_tif(frame_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Parameters and Model\n",
    "Specify Post-Processing as by the parameter file you trained the model with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model instantiated.\n",
      "Model SHA-1 hash: 3dc4813290eac0af7b8653ef1dc37f12c9de73ba\n",
      "Loaded pretrained model: /home/lucas/git/thesisjupyterbooks/temp/Artur_Bundle/model_out_0.pt\n"
     ]
    }
   ],
   "source": [
    "param = decode.utils.param_io.load_params(param_path)\n",
    "model = decode.neuralfitter.models.SigmaMUNet.parse(param)\n",
    "model = decode.utils.model_io.LoadSaveModel(model,\n",
    "                                              input_file=model_path,\n",
    "                                              output_file=None).load_init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up Pre- and Post-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'frames' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-1-328312006a26>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;31m# determine extent of frame and its dimension\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0mframe_extent\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m0.5\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mframes\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msize\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m2\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0;36m0.5\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m0.5\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mframes\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msize\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0;36m0.5\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      3\u001B[0m \u001B[0mframe_size\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtuple\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mframes\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msize\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m2\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;31m# setup frame processing as by the parameter with which the model was trained\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'frames' is not defined"
     ]
    }
   ],
   "source": [
    "# determine extent of frame and its dimension\n",
    "frame_extent = ((-0.5, frames.size(-2) - 0.5), (-0.5, frames.size(-1) - 0.5))\n",
    "frame_size = tuple(frames.size()[-2:])\n",
    "\n",
    "# setup frame processing as by the parameter with which the model was trained\n",
    "frame_proc = decode.neuralfitter.scale_transform.AmplitudeRescale.parse(param)\n",
    "\n",
    "# Setup post-processing\n",
    "# It's a sequence of backscaling, relative to abs. coord conversion and frame2emitter conversion\n",
    "post_proc = decode.neuralfitter.utils.processing.TransformSequence([\n",
    "    \n",
    "    decode.neuralfitter.scale_transform.InverseParamListRescale.parse(param),\n",
    "    \n",
    "    decode.neuralfitter.coord_transform.Offset2Coordinate(xextent=frame_extent[0],\n",
    "                                                            yextent=frame_extent[1],\n",
    "                                                            img_shape=frame_size),\n",
    "    \n",
    "    decode.neuralfitter.post_processing.LookUpPostProcessing(raw_th=post_raw_th,\n",
    "                                                               xy_unit='px', \n",
    "                                                               px_size=param.Camera.px_size)\n",
    "    \n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:01<00:00,  9.50it/s]\n"
     ]
    }
   ],
   "source": [
    "infer = decode.neuralfitter.Infer(model=model, ch_in=param.HyperParameter.channels_in,\n",
    "                                    frame_proc=frame_proc, post_proc=post_proc,\n",
    "                                    device=device)\n",
    "\n",
    "emitter = infer.forward(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EmitterSet\n",
      "::num emitters: 158000\n",
      "::xy unit: px\n",
      "::frame range: 0 - 999\n",
      "::spanned volume: [   0.20551562    0.19100158 -105.857735  ] - [ 62.863    63.06127 119.09278]\n"
     ]
    }
   ],
   "source": [
    "# check on the output\n",
    "print(emitter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export EmitterSet\n",
    "e.g. as CSV, or as pickle object for reload in another notebook etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# csv export\n",
    "decode.utils.emitter_io.save_csv('emitter.csv', emitter.to_dict())\n",
    "\n",
    "# pickle\n",
    "emitter.save('emitter.pl')  # can be loaded via 'decode.EmitterSet.load('emitter.pl')'\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:deepsmlm_cuda_py38_pt15]",
   "language": "python",
   "name": "conda-env-deepsmlm_cuda_py38_pt15-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}